#!/bin/bash
#
# ---------------------------------------- #
#   Daniel Smith - February 18th, 2022     #
#   Baylor College of Medicine             #
#   Creative Commons License BY-SA 4.0     #
# ---------------------------------------- #
#


#----------------------------------------------------------
# Default options for the script's parameters.
#----------------------------------------------------------
DEST=""; INFILE=""; TEST=0; CONFIG=""; EMAIL="";
STORE="INTELLIGENT_TIERING"; ROTATE="5/7/6/12/5"; 


#----------------------------------------------------------
# Help text
#----------------------------------------------------------
usage () {
cat <<-EOM

  THIS SCRIPT WILL DELETE FILES. THE AUTHOR MAKES NO GUARANTEE 
  IT WILL ONLY DELETE THE RIGHT ONES. USE AT YOUR OWN RISK.
  
  Usage: $0 -d s3://bucket/path/prefix_%.tgz [OPTIONS]
  
      -d --dest    Destination path template for backups.
      -r --rotate  Rotation scheme in recent/day/week/month/year format.
                   [Default: $ROTATE]
  
      -a --add     A file or folder to push to the backup destination.
      -e --email   Use Amazon SES to send error messages to this address.
      -t --test    Do not change files - dry run only.
      -s --store   S3 storage class to use. [Default: $STORE]
      -c --config  Path to the AWS config file to use.
      -h --help    Print this help message and exit.
  
  
  Removes old versions of backups according to the user's data retention
  policy (keep X daily, Y weekly, Z monthly, etc).
  
  See https://github.com/dansmith01/backstack for additional help.
  
  Example:
    $0 --dest s3://xyz-backup/x_%.tgz --rotate /3/6 --test
  
    s3://xyz-backup/x_2022-01-01-0500.tgz    KEEP
    s3://xyz-backup/x_2022-01-02-0500.tgz    DROP
    s3://xyz-backup/x_2022-01-06-0500.tgz    DROP
    s3://xyz-backup/x_2022-01-07-0500.tgz    KEEP
    s3://xyz-backup/x_2022-01-08-0500.tgz    KEEP
    s3://xyz-backup/x_2022-01-09-0500.tgz    KEEP
  
  This script relies on datestamps in the file's name. It completely ignores any
  creation/modification file metadata. The current date also does not factor
  into which files are kept or discarded; it keeps the most recent N files from
  each time category regardless of how old they are. Autogenerated timestamp is
  the current timezone's date/time in YYYY-mm-dd-HHMM format.
  
EOM
}


#--------------------------------------------------------------------
# Create a directory for our temporary files.
#--------------------------------------------------------------------
T=`mktemp -d`


#----------------------------------------------------------
# Write errors to STDERR, and optionally email
#----------------------------------------------------------
CMD="$0 $*"
errmsg () {

  >&2 echo "Error: $1\n"
  
  if [ -n "$EMAIL" -a "$TEST" -eq 0 ]
  then
    aws ses send-email                        \
      --from    "$EMAIL"                      \
      --to      "$EMAIL"                      \
      --subject "Backup Error for $DEST"      \
      --text    "`uname -n`: $CMD\nError: $1"
  fi
}



#--------------------------------------------------------------------
# Parse command line options into variables.
#--------------------------------------------------------------------
[ $# -ne 0 ] || { usage; exit 0; }
while [ $# -gt 0 ]; do
  case "$1" in
    -d|--dest)    DEST="$2";            shift 2 ;;
    -r|--rotate)  ROTATE="$2";          shift 2 ;;
    -a|--add)     INFILE="$2";          shift 2 ;;
    -e|--email)   EMAIL="$2";           shift 2 ;;
    -c|--config)  CONFIG="$2";          shift 2 ;;
    -s|--store)   STORE="$2";           shift 2 ;;
    -t|--test)    TEST=1;               shift 1 ;;
    -h|--help)    usage;                exit 0  ;;
    *) errmsg "Invalid Parameter '$1'"; exit 1
  esac
done


#--------------------------------------------------------------------
# Parse apart the destination template string
#--------------------------------------------------------------------
SUFFIX=${DEST##*%}
PREFIX=${DEST%%%*}
BUCKET=${DEST##*s3://}
BUCKET=${BUCKET%%/*}


#--------------------------------------------------------------------
# Sanity check arguments.
#--------------------------------------------------------------------
[ -n "$DEST" ]                   || { errmsg "--dest is required.";                     exit 1; }
[ -n "$SUFFIX" ]                 || { errmsg "--dest must include a file extension.";   exit 1; }
[ "$SUFFIX" != "$DEST" ]         || { errmsg "--dest must include the % placeholder.";  exit 1; }
[ -z "${DEST%s3://*}" ]          || { errmsg "--dest must start with 's3://'.";         exit 1; }
[ "${BUCKET#*%}" = "$BUCKET" ]   || { errmsg "Invalid destination bucket '$BUCKET'.";   exit 1; }
[ -z "$INFILE" -o -r "$INFILE" ] || { errmsg "Can't read --add file '$INFILE'.";        exit 1; }
[ -z "$CONFIG" -o -r "$CONFIG" ] || { errmsg "Can't read --config file '$CONFIG'.";     exit 1; }

IFS=/ read RECENT DAILY WEEKLY MONTHLY YEARLY <<< "$ROTATE"
case ${RECENT:=0}  in *[!0-9]*) errmsg "recent must be an integer.";   exit 1 ;; esac
case ${DAILY:=0}   in *[!0-9]*) errmsg "daily must be an integer.";    exit 1 ;; esac
case ${WEEKLY:=0}  in *[!0-9]*) errmsg "weekly must be an integer.";   exit 1 ;; esac
case ${MONTHLY:=0} in *[!0-9]*) errmsg "monthly must be an integer.";  exit 1 ;; esac
case ${YEARLY:=0}  in *[!0-9]*) errmsg "yearly must be an integer.";   exit 1 ;; esac

[ "$RECENT$DAILY$WEEKLY$MONTHLY$YEARLY" != "00000" ] || { errmsg "--rotate is required."; exit 1; }


#--------------------------------------------------------------------
# Check our connection to AWS.
#--------------------------------------------------------------------
[ -z "$CONFIG" ] || export AWS_CONFIG_FILE="$CONFIG"
[ -x "$(command -v aws)" ] || { errmsg "Could not find the 'aws' cli executable."; exit 1; }
aws sts get-caller-identity > /dev/null
[ $? -eq 0 ] || { errmsg "Can't connect to Amazon Web Services."; exit 1; }


#--------------------------------------------------------------------
# Upload the new achive to S3, unless in test mode
#--------------------------------------------------------------------
if [ -n "$INFILE"]
then

  if ["$TEST" -eq 1]
  then
    #--------------------------------------------------------------------
    # Just simulate the new file being added when in test mode
    #--------------------------------------------------------------------
    echo "${PREFIX}$(date '+%F-%H%M')$SUFFIX" > $T/initial
  else
    
    #--------------------------------------------------------------------
    # Compress a directory into a tarball.
    #--------------------------------------------------------------------
    if [ -d "$INFILE" ]
    then
      tar -C `dirname "$INFILE"` -czf "$T/infile" `basename "$INFILE"`
      INFILE="$T/infile"
    fi
    
    #--------------------------------------------------------------------
    # Upload to S3, renaming based on prefix and timestamp.
    #--------------------------------------------------------------------
    aws s3 cp "$INFILE" "${PREFIX}$(date '+%F-%H%M')$SUFFIX" --storage-class "$STORE"
    [ $? -eq 0 ] || { errmsg "'aws s3 cp' had non-zero exit status."; exit 1; }
    
  fi

fi


#--------------------------------------------------------------------
# Fetch the current archive names from S3 and parse out the dates.
#--------------------------------------------------------------------
aws s3 ls --recursive "$PREFIX" > $T/s3_ls
[ $? -le 1 ] || { errmsg "'aws s3 ls' had non-zero exit status."; exit 1; }

awk '{print "s3://'$BUCKET'/"$4}' $T/s3_ls >> $T/initial
cut -c $(( ${#PREFIX} + 1 ))-$(( ${#PREFIX} + 10 )) $T/initial     |\
  date '+%F%t%Y-%U%t%Y-%m%t%Y' -f - > $T/extract
paste $T/extract $T/initial | sort -r > $T/search


#--------------------------------------------------------------------
# Now we have the following table, sorted from NEWEST -> OLDEST
#--------------------------------------------------------------------
#|  DAY         WEEK     MONTH    YEAR  FILE
#|  2022-02-09  2022-06  2022-02  2022  s3://x/y_2022-02-09-1100.tgz
#|  2022-02-08  2022-06  2022-02  2022  s3://x/y_2022-02-08-1000.tgz
#|  2022-02-07  2022-06  2022-02  2022  s3://x/y_2022-02-07-1200.tgz
#|  2022-01-31  2022-05  2022-01  2022  s3://x/y_2022-01-31-0800.tgz


#--------------------------------------------------------------------
# Keep the most recent unique N entries from each column.
#--------------------------------------------------------------------
uniq            $T/search | head -n $RECENT  > $T/recent
uniq -w 10      $T/search | head -n $DAILY   > $T/daily
uniq -w 8  -f 1 $T/search | head -n $WEEKLY  > $T/weekly
uniq -w 8  -f 2 $T/search | head -n $MONTHLY > $T/monthly
uniq -w 5  -f 3 $T/search | head -n $YEARLY  > $T/yearly


#--------------------------------------------------------------------
# Intersect the lists to keep, then generate the list to drop.
#--------------------------------------------------------------------
cat $T/recent $T/daily $T/weekly $T/monthly $T/yearly |\
  cut -f 5 | sort -u | grep -v "^$" > $T/keep

sort -u $T/initial | grep -v "^$" > $T/initial_sorted
comm -23 $T/initial_sorted $T/keep > $T/drop


#--------------------------------------------------------------------
# Remove unneeded archives, or just display our plans to the user.
#--------------------------------------------------------------------
if [ "$TEST" -eq 1 ]
then
  cat $T/keep | sed "s .* &\tKEEP " >> $T/log
  cat $T/drop | sed "s .* &\tDROP " >> $T/log
  [ -s $T/log ] || echo "(none)"    >> $T/log
  cat $T/log | sort
else
  xargs -a $T/drop -d'\n' -n 1 --no-run-if-empty -I{} \
    sh -c 'aws s3 rm "$1"; [ $? -eq 0 ] || exit 255' sh {} 
fi


#--------------------------------------------------------------------
# Delete our temporary files and directory.
#--------------------------------------------------------------------
rm -rf $T
